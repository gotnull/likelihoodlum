# ğŸ² Likelihoodlum

**Detect whether a GitHub repository's code was likely written by an LLM.**

Likelihoodlum analyzes a repository's commit history and uses timing-based heuristics to estimate the likelihood that the code was generated by a large language model rather than written by a human.

The core idea is simple: **humans type slow, LLMs don't.** If someone is pushing hundreds of lines of polished code every few minutes, something's up.

---

## How It Works

Likelihoodlum fetches commit history via the GitHub API and scores the repo on a 0â€“100 scale across five heuristics:

| Signal | Max Points | What It Measures |
|---|---|---|
| **Code Velocity** | 35 | Lines changed per minute between consecutive commits. Humans do ~30 LoC/hr; LLM-assisted work blows past 200+. |
| **Session Productivity** | 20 | Groups commits into coding sessions (>2hr gap = new session) and measures aggregate output. |
| **Burst Detection** | 15 | Flags sessions where >500 lines appeared in under 30 minutes. |
| **Commit Size Uniformity** | 15 | LLM dumps tend to be uniformly large. Human commits vary (small fixes, big features, etc). |
| **Commit Message Patterns** | 15 | Catches generic messages like *"Add feature"*, *"Implement X"*, *"Update file.py"* â€” the kind LLMs love. |

### Verdicts

| Score | Verdict |
|---|---|
| 75â€“100 | ğŸ¤– Very likely LLM-generated |
| 50â€“74 | ğŸ¤– Likely LLM-assisted |
| 30â€“49 | ğŸ¤” Possibly LLM-assisted |
| 15â€“29 | ğŸ‘¤ Likely human-written |
| 0â€“14 | ğŸ‘¤ Almost certainly human-written |

## Installation

**Zero dependencies** â€” runs on Python 3.10+ with only the standard library.

```bash
git clone https://github.com/gotnull/likelihoodlum.git
cd likelihoodlum
```

Optionally install `python-dotenv` for `.env` file support (a built-in fallback parser is included if you don't):

```bash
pip install python-dotenv
```

## Setup

### GitHub Token (Recommended)

Without a token you're limited to 60 API requests/hour. With one, you get 5,000/hr.

**Option A: `.env` file** (recommended)

```bash
cp .env.example .env
# Edit .env and add your token
```

```
GITHUB_TOKEN=ghp_your_token_here
```

The `.env` file is gitignored by default â€” your token stays safe.

**Option B: Environment variable**

```bash
export GITHUB_TOKEN="ghp_your_token_here"
```

**Option C: CLI flag**

```bash
python3 llm_detector.py owner/repo --token ghp_your_token_here
```

### Generating a Token

1. Go to [GitHub â†’ Settings â†’ Developer settings â†’ Personal access tokens](https://github.com/settings/tokens)
2. Generate a new token (classic) with `public_repo` scope (or `repo` for private repos)
3. Copy it â€” you won't see it again

## Usage

```bash
# Basic â€” analyze a public repo
python3 llm_detector.py owner/repo

# Full GitHub URL works too
python3 llm_detector.py https://github.com/owner/repo

# Analyze more commits (default is 200)
python3 llm_detector.py owner/repo --max-commits 1000

# Target a specific branch
python3 llm_detector.py owner/repo --branch develop

# Machine-readable JSON output
python3 llm_detector.py owner/repo --json

# Go big
python3 llm_detector.py owner/repo --max-commits 5000 --json > report.json
```

### Example Output

```
============================================================
  LLM Code Detector Report
  Repository: someone/suspicious-project
============================================================

ğŸ“Š Commits analyzed: 200
ğŸ“… Time span: 12 days
ğŸ‘¥ Authors: 1
   â€¢ devguy42: 200 commits

âš¡ Velocity (lines/min between commits):
   Median: 9.40  (â‰ˆ 564 lines/hr)
   Mean:   14.22
   Max:    87.50
   Intervals above suspicious threshold: 143/198

ğŸ”¥ Fastest commit intervals:
   a1b2c3d4â†’e5f6g7h8  1750 lines in 20.0 min = 87.5 l/min âš ï¸
   ...

ğŸ’¬ Commit messages matching LLM patterns: 168/200 (84.0%)
   â€¢ "Add user authentication module"
   â€¢ "Implement API endpoint for data retrieval"
   â€¢ "Update README.md"

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ğŸ¯ LLM Likelihood Score: 82/100
  ğŸ¤– Very likely LLM-generated
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“ Reasoning:
   â€¢ Median velocity is extremely high (9.4 lines/min â‰ˆ 564 lines/hr)
   â€¢ 72% of commit intervals show very high velocity
   â€¢ Median session productivity is extreme (11.2 lines/min)
   â€¢ 84% of commit messages match LLM-typical patterns
   â€¢ 6 burst sessions detected (>500 lines in <30 min)

âš   Disclaimer: This is a heuristic analysis and NOT definitive proof.
   Fast coding can also indicate copy-paste, boilerplate generators,
   IDE scaffolding, or simply an experienced developer.
```

## API Rate Limits

Each commit requires one API call for detailed stats. Keep this in mind:

| Auth | Rate Limit | Max Commits Comfortable |
|---|---|---|
| No token | 60/hr | ~50 |
| With token | 5,000/hr | ~4,000 |

## Limitations & Disclaimer

This tool uses **heuristics, not magic**. A high score doesn't prove LLM usage, and a low score doesn't disprove it.

False positives can come from:
- Copy-pasting code from other projects
- IDE/framework scaffolding and boilerplate generators
- Squashed/rebased commits that compress work
- An experienced developer who plans before coding
- Generated code (protobufs, OpenAPI, etc.)

False negatives can come from:
- LLM-generated code committed slowly or in small chunks
- Human-edited LLM output committed as normal work
- Commits with manual timing that mimics human patterns

**Use responsibly.** This is a curiosity tool, not a courtroom exhibit.

## License

MIT â€” do whatever you want with it.

## Contributing

Found a new heuristic? PRs welcome. Ideas:

- Diff complexity scoring (entropy analysis)
- File-type breakdown (LLMs love generating configs)
- Comment density analysis
- Code style consistency metrics
- Cross-referencing with known LLM output patterns